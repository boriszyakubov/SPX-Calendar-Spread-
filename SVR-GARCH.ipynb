{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AlgorithmImports import *\n",
    "from QuantConnect.DataSource import *\n",
    "from QuantConnect.Research import QuantBook\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd \n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from arch import arch_model\n",
    "import pandas as pd \n",
    "import scipy.optimize as spop\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = QuantBook()\n",
    "\n",
    "spx = qb.AddIndex('SPX').Symbol ##Defines SPX index symbol object\n",
    "\n",
    "start_time = datetime(2005, 1, 1) ##Start date for SPX symbol object data\n",
    "end_time = datetime.now() ##End date for SPX symbol object data (current date)\n",
    "\n",
    "single_history_df = qb.History(spx, start_time, end_time) \n",
    "subset_history_df = qb.History([spx], start_time, end_time)\n",
    "\n",
    "all_history_df = qb.History(qb.Securities.Keys, start_time, end_time) ##Gets trade data, including closing price data, for SPX Index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_history_df.reset_index(inplace=True) \n",
    "\n",
    "all_history_df['time'] = pd.to_datetime(all_history_df['time']).dt.date ##Converts string time stamp data to datetime \n",
    "\n",
    "all_history_df = all_history_df.drop_duplicates(subset = \"time\", keep = \"last\") ##Gets only the last quoted closing price data for SPX Index \n",
    "\n",
    "\n",
    "##Bellow discards all columns of all_history_df besides SPX Closing price data \n",
    "\n",
    "all_history_df = all_history_df.drop(['high', 'low', 'open'], axis = 1)\n",
    "\n",
    "all_history_df.set_index('time', inplace = True)\n",
    "\n",
    "all_history_df.drop(['symbol'], axis = 1) \n",
    "\n",
    "\n",
    "all_history_df.index = pd.to_datetime(all_history_df.index)\n",
    "\n",
    "all_history_df = all_history_df.resample('M').last()  ##Resamples daily return data to be monthly return data instead \n",
    "\n",
    "new = all_history_df['close'] = pd.to_numeric(all_history_df['close'], errors='coerce') ##Creates another dataframe, new, that will be used to train SVR-GARCH model\n",
    "\n",
    "\n",
    "new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = 100 * (new.pct_change()[1:]) ##Calculates monthly returns for SPX Index \n",
    "\n",
    "realized_vol = ret.rolling(5).std() ##Calculate realized volatility (rolling)\n",
    "\n",
    "realized_vol = pd.DataFrame(realized_vol) ##Creates dataframe with realized volatility values to be used by SVR-GARCH model \n",
    "\n",
    "realized_vol.reset_index(drop=True, inplace=True)\n",
    "returns_svm = ret ** 2 ##Squares  monthly returns to be used in SVR-GARCH model\n",
    "returns_svm = returns_svm.reset_index()\n",
    "del returns_svm['time'] \n",
    "\n",
    "ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([realized_vol, returns_svm], axis=1, ignore_index=True)\n",
    "X \n",
    "X = X.reset_index() \n",
    "X.drop('index', axis=1, inplace=True) \n",
    "\n",
    "\n",
    "realized_vol = realized_vol.dropna().reset_index()\n",
    "realized_vol.drop('index', axis=1, inplace=True)\n",
    "\n",
    "svr_lin = SVR(kernel='linear') #Initializes SVR-GARCH Linear \"Kernel Trick\" for better model fitting \n",
    "\n",
    "n = 30 #Initializes a train-test split, with the testing set being the last 30 months of the time period of interest (80/20 train/test split)\n",
    "\n",
    "X_clean = X.dropna() ##Creates a X_clean data frame of realized volatility and monthly return values, but drops NA and null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_grid = {'gamma': sp_rand(),\n",
    "'C': sp_rand(),\n",
    "'epsilon': sp_rand()} ##Initializes parametric grid \n",
    "\n",
    "clf = RandomizedSearchCV(svr_lin, para_grid) ##Utilizes randomized search as part of SVR-GARCH \n",
    "\n",
    "clf.fit(X_clean.iloc[:-n].values,\n",
    "realized_vol.iloc[1:-(n-1)].values.reshape(-1,)) ##Fits SVR-GARCH model to the data on SPX monthly returns and volatility wihin te train set \n",
    "\n",
    "predict_svr_lin = clf.predict(X_clean.iloc[-n:]) ##Predicts volatility using fitted SVR-GARCH on test set \n",
    "\n",
    "predict_svr_lin = pd.DataFrame(predict_svr_lin) ## Puts predicted volatility using fitted SVR-GARCH on test set into a dataframe \n",
    "\n",
    "predict_svr_lin.index = ret.iloc[-n:].index\n",
    "\n",
    "\n",
    "rmse_svr = np.sqrt(mean_squared_error(realized_vol.iloc[-n:] / 100,\n",
    "predict_svr_lin / 100)) ##Scales the predicted SVR-GACH volatility down by a factor of 100, consistent with Machine Learning for Financial Risk Management with Python by Abdullah Karasan\n",
    "\n",
    "rmse_svr ##RMSE was calculated to be 0.003844866195521824 on the testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Bellow function turns SVR-GARCH predicted volatility model into a function to be used within a function to predict cumilative volatility from the present day to some date in the future\n",
    "def predict_volatility_to_date(end_date_str, new):\n",
    "    # Convert end_date to datetime if it's a string\n",
    "    if isinstance(end_date_str, str):\n",
    "        end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "    else:\n",
    "        end_date = end_date_str\n",
    "\n",
    "    # Ensure current_date is a datetime object\n",
    "    current_date = datetime.now()\n",
    "\n",
    "    # Calculate the number of months to predict\n",
    "    year_diff = end_date.year - current_date.year\n",
    "    month_diff = end_date.month - current_date.month\n",
    "    months_to_predict = year_diff * 12 + month_diff\n",
    "\n",
    "    #Data Preparation; see above \n",
    "    ret = 100 * (new.pct_change()[1:])\n",
    "    realized_vol = ret.rolling(5).std()\n",
    "    realized_vol = realized_vol.dropna().reset_index(drop=True)\n",
    "    \n",
    "    X_clean = realized_vol.dropna()\n",
    "\n",
    "    #Train SVR-GARCH Model\n",
    "    svr_lin = SVR(kernel='linear')\n",
    "    para_grid = {'gamma': sp_rand(), 'C': sp_rand(), 'epsilon': sp_rand()}\n",
    "    clf = RandomizedSearchCV(svr_lin, para_grid)\n",
    "    clf.fit(X_clean.values.reshape(-1, 1), realized_vol.values.reshape(-1,))\n",
    "\n",
    "    #Initialize a DataFrame to store predictions\n",
    "    predictions = pd.DataFrame()\n",
    "\n",
    "    #Initialize the rolling window with the last 12 months of historical data\n",
    "    rolling_window = X_clean[-12:]\n",
    "\n",
    "    #Loop through each month and prepare data for prediction\n",
    "    for i in range(months_to_predict):\n",
    "        # Generate feature from the current rolling window\n",
    "        feature_value = rolling_window.mean()  # Example using mean; adjust as needed\n",
    "\n",
    "        #Predict the volatility for this month\n",
    "        predicted_vol = clf.predict([[feature_value]])\n",
    "\n",
    "        #Store the prediction\n",
    "        iter_date = current_date + relativedelta(months=i)\n",
    "        predictions = predictions.append({'Date': iter_date, 'PredictedVol': predicted_vol[0]}, ignore_index=True)\n",
    "\n",
    "        #Update the rolling window\n",
    "        if len(rolling_window) >= 12:\n",
    "            rolling_window = rolling_window[1:]  # Drop the oldest month\n",
    "        rolling_window = rolling_window.append(pd.Series(predicted_vol[0]))\n",
    "        \n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cumulative_volatility(end_date_str, new):\n",
    "    # Convert end_date to datetime if it's a string\n",
    "    if isinstance(end_date_str, str):\n",
    "        end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "    else:\n",
    "        end_date = end_date_str\n",
    "\n",
    "    # Ensure current_date is a datetime object\n",
    "    current_date = datetime.now()\n",
    "\n",
    "    # Calculate the number of months to predict\n",
    "    year_diff = end_date.year - current_date.year\n",
    "    month_diff = end_date.month - current_date.month\n",
    "    months_to_predict = year_diff * 12 + month_diff + (1 if end_date.day > current_date.day else 0)\n",
    "\n",
    "    # Data Preparation and Feature Engineering\n",
    "    ret = 100 * (new.pct_change()[1:])\n",
    "    realized_vol = ret.rolling(5).std()\n",
    "    realized_vol = realized_vol.dropna().reset_index(drop=True)\n",
    "    \n",
    "    X_clean = realized_vol.dropna()\n",
    "\n",
    "    # Train SVR Model\n",
    "    svr_lin = SVR(kernel='linear')\n",
    "    para_grid = {'gamma': sp_rand(), 'C': sp_rand(), 'epsilon': sp_rand()}\n",
    "    clf = RandomizedSearchCV(svr_lin, para_grid)\n",
    "    clf.fit(X_clean.values.reshape(-1, 1), realized_vol.values.reshape(-1,))\n",
    "\n",
    "    # Initialize cumulative volatility\n",
    "    cumulative_volatility = 0\n",
    "\n",
    "    # Initialize the rolling window with the last 12 months of historical data\n",
    "    rolling_window = X_clean[-6:]\n",
    "\n",
    "    # Loop through each month and prepare data for prediction\n",
    "    for i in range(months_to_predict):\n",
    "        # Generate feature from the current rolling window\n",
    "        feature_value = rolling_window.mean()  # Example using mean; adjust as needed\n",
    "\n",
    "        # Predict the volatility for this month\n",
    "        predicted_vol = clf.predict([[feature_value]])\n",
    "\n",
    "        # Update the rolling window\n",
    "        if len(rolling_window) >= 12:\n",
    "            rolling_window = rolling_window[1:]  #Drop the oldest month\n",
    "        rolling_window = rolling_window.append(pd.Series(predicted_vol[0]))\n",
    "\n",
    "        #Calculate the number of days to prorate in the first and last month\n",
    "        days_in_month = (current_date + relativedelta(months=i+1, days=-1)).day\n",
    "        start_day = current_date.day if i == 0 else 1\n",
    "        end_day = end_date.day if i == months_to_predict - 1 else days_in_month\n",
    "        days_to_prorate = end_day - start_day + 1\n",
    "\n",
    "        # Prorate the volatility for partial months\n",
    "        prorated_vol = (predicted_vol[0] / days_in_month) * days_to_prorate\n",
    "        cumulative_volatility += prorated_vol\n",
    "\n",
    "    return cumulative_volatility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cumil_vol = predict_cumulative_volatility('2024-3-3', new) ##Example predicted SVR-GARCH cumilative volatility \n",
    "\n",
    "cumil_vol / 100 ##Scales the predicted cumilative SVR-GACH volatility down by a factor of 100, consistent with Machine Learning for Financial Risk Management with Python by Abdullah Karasan"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
